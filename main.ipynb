{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import brown\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading brown: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1135)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 45872\n",
      "Test samples: 11468\n"
     ]
    }
   ],
   "source": [
    "# corpus = list(nltk.corpus.brown.tagged_sents())\n",
    "corpus = list(brown.tagged_sents(tagset='universal'))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "split = int(0.8 * len(corpus))\n",
    "\n",
    "train = corpus[:split]\n",
    "test = corpus[split:]\n",
    "\n",
    "print('Train samples:', len(train))\n",
    "print('Test samples:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_data(sequences):\n",
    "    x = []\n",
    "    y = []\n",
    "    w = set()\n",
    "    t = set()\n",
    "    for sequence in sequences:\n",
    "        sequence_x = []\n",
    "        sequence_y = []\n",
    "        for word, tag in sequence:\n",
    "            sequence_x.append(word)\n",
    "            sequence_y.append(tag)\n",
    "            w.add(word)\n",
    "            t.add(tag)\n",
    "        x.append(sequence_x)\n",
    "        y.append(sequence_y)\n",
    "    return x, y, w, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, train_words, train_tagset = rearrange_data(train)\n",
    "test_x, test_y, test_words, test_tagset = rearrange_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_counts(sequences_A, sequences_B):\n",
    "    emission_counts = {}\n",
    "\n",
    "    for sequence_A, sequence_B in zip(sequences_A, sequences_B):\n",
    "        \n",
    "        for a, b in zip(sequence_A, sequence_B):\n",
    "            \n",
    "            if a not in emission_counts.keys():\n",
    "                emission_counts[a] = {}\n",
    "            \n",
    "            if b in emission_counts[a].keys():\n",
    "                emission_counts[a][b]+=1\n",
    "            else:\n",
    "                emission_counts[a][b]=1\n",
    "    \n",
    "    return emission_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_counts(sequences):\n",
    "    tag_unigrams = {}\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        \n",
    "        for tag in sequence:\n",
    "            \n",
    "            if tag in tag_unigrams.keys():\n",
    "                tag_unigrams[tag]+=1\n",
    "            else:\n",
    "                tag_unigrams[tag]=1\n",
    "                \n",
    "    return tag_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_counts_brown(sequences):\n",
    "    tag_bigrams = {}\n",
    "\n",
    "    for sequence in sequences:\n",
    "        \n",
    "        l = len(sequence)\n",
    "        \n",
    "        for index in range(l-1):\n",
    "            \n",
    "            a,b = sequence[index], sequence[index+1]\n",
    "            \n",
    "            if (a,b) in tag_bigrams.keys():\n",
    "                tag_bigrams[(a,b)] += 1\n",
    "            else:\n",
    "                tag_bigrams[(a,b)] = 1\n",
    "                \n",
    "    return tag_bigrams   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starting_counts(sequences):\n",
    "    tag_starts = {}\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        if sequence[0] in tag_starts.keys():\n",
    "            tag_starts[sequence[0]]+=1\n",
    "        else:\n",
    "            tag_starts[sequence[0]]=1\n",
    "\n",
    "    return tag_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ending_counts(sequences):\n",
    "    tag_ends = {}\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        \n",
    "        if sequence[-1] in tag_ends.keys():\n",
    "            tag_ends[sequence[-1]]+=1\n",
    "        else:\n",
    "            tag_ends[sequence[-1]]=1\n",
    "    \n",
    "    return tag_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_counts = pair_counts(train_y, train_x)\n",
    "tag_unigrams = unigram_counts(train_y)\n",
    "tag_bigrams = bigram_counts_brown(train_y)\n",
    "tag_starts = starting_counts(train_y)\n",
    "tag_ends = ending_counts(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges Brown model: 168\n"
     ]
    }
   ],
   "source": [
    "brown_model = HiddenMarkovModel(name=\"brown-hmm-tagger\")\n",
    "\n",
    "states = dict()\n",
    "for tag, words in emission_counts.items():\n",
    "    probs = {w:c / tag_unigrams[tag] for w, c in words.items()}\n",
    "    emissions = DiscreteDistribution(probs)\n",
    "    state = State(emissions, name=tag)\n",
    "    brown_model.add_states(state)\n",
    "    states[tag] = state\n",
    "\n",
    "n = sum(tag_starts.values())\n",
    "for tag, counts in tag_starts.items():\n",
    "    brown_model.add_transition(brown_model.start, states[tag], counts / n)\n",
    "\n",
    "for (tag1, tag2), counts in tag_bigrams.items():\n",
    "    brown_model.add_transition(states[tag1], states[tag2], counts / tag_unigrams[tag1])\n",
    "\n",
    "for tag, counts in tag_ends.items():\n",
    "    brown_model.add_transition(states[tag], brown_model.end, counts / tag_unigrams[tag])\n",
    "\n",
    "brown_model.bake()\n",
    "\n",
    "print('Edges Brown model:', brown_model.edge_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknown_brown(sequence, vocabulary):\n",
    "    return [w if w in vocabulary else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding_brown(X, model, vocabulary):\n",
    "    _, state_path = model.viterbi(replace_unknown_brown(X, vocabulary))\n",
    "    return [state[1].name for state in state_path[1:-1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_brown(X, Y, model, vocabulary):\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding_brown(observations, model, vocabulary)\n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 97.54%\n",
      "testing accuracy: 96.06%\n"
     ]
    }
   ],
   "source": [
    "training_acc = accuracy_brown(train_x, train_y, brown_model, train_words)\n",
    "print(\"training accuracy: {:.2f}%\".format(100 * training_acc))\n",
    "\n",
    "testing_acc = accuracy_brown(test_x, test_y, brown_model, train_words)\n",
    "print(\"testing accuracy: {:.2f}%\".format(100 * testing_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where ADV\n",
      "can VERB\n",
      "I PRON\n",
      "find VERB\n",
      "the DET\n",
      "supermarket NOUN\n",
      "in ADP\n",
      "this DET\n",
      "town NOUN\n",
      "? .\n"
     ]
    }
   ],
   "source": [
    "# sentence = [\"I\", \"love\", \"you\"]\n",
    "sentence = ['Where', 'can', 'I', 'find', 'the', 'supermarket', 'in', 'this', 'town', '?']\n",
    "\n",
    "tags = simplify_decoding_brown(sentence, brown_model, train_words)\n",
    "for word, tag in zip(sentence, tags):\n",
    "    print(word, tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
